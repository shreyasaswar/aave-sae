{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc0b1d14-5359-4bc2-aec9-ebd01558a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import TextVectorization, Input, Embedding, LSTM, Dense, Concatenate, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dd23026-df08-4724-9cfa-659e1c61013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Please install GPU version of TF, as TensorFlow did not find a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availbility\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Explicitly set GPU as preferred device (if available)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF, as TensorFlow did not find a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "038c22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data Reading\n",
    "dataframe = pd.read_csv('pro_corpus.csv')\n",
    "assert 'AAVE' in dataframe.columns and 'SAE' in dataframe.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e00810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparing the dataset\n",
    "aave_texts = dataframe['AAVE'].str.lower().tolist()\n",
    "sae_texts = dataframe['SAE'].str.lower().tolist()\n",
    "\n",
    "# Split the data into train and test sets\n",
    "aave_train, aave_test, sae_train, sae_test = train_test_split(\n",
    "    aave_texts, sae_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the train and test data into TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'aave': aave_train,\n",
    "    'sae': sae_train\n",
    "})\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'aave': aave_test,\n",
    "    'sae': sae_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e2f94ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'aave_texts' and 'sae_texts' are your datasets\n",
    "aave_lengths = [len(sentence.split()) for sentence in aave_texts]\n",
    "sae_lengths = [len(sentence.split()) for sentence in sae_texts]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(aave_lengths, bins=30)\n",
    "plt.title('Distribution of AAVE Sentence Lengths')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Number of Sentences')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(sae_lengths, bins=30)\n",
    "plt.title('Distribution of SAE Sentence Lengths')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45f27bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BUFFER_SIZE = len(aave_train)  # Use the size of the train dataset\n",
    "\n",
    "# Adjust batch sizes\n",
    "train_batch_size = 16\n",
    "test_batch_size = 4\n",
    "\n",
    "# Shuffle and batch the train dataset\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(train_batch_size, drop_remainder=True)\n",
    "\n",
    "# Batch the test dataset\n",
    "test_dataset = test_dataset.batch(test_batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97b6a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization\n",
    "aave_vectorization = TextVectorization(output_mode='int', output_sequence_length=30)\n",
    "sae_vectorization = TextVectorization(output_mode='int', output_sequence_length=30)\n",
    "\n",
    "aave_texts = train_dataset.map(lambda x: x['aave'])\n",
    "sae_texts = train_dataset.map(lambda x: x['sae'])\n",
    "\n",
    "aave_vectorization.adapt(aave_texts)\n",
    "sae_vectorization.adapt(sae_texts)\n",
    "\n",
    "aave_vocab_size = len(aave_vectorization.get_vocabulary())\n",
    "sae_vocab_size = len(sae_vectorization.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e75af1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "num_heads = 4  # Number of attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1198498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Enhanced Model\n",
    "# Encoder\n",
    "encoder_input = Input(shape=(None,), dtype='int64', name='encoder_input')\n",
    "encoder_embedding = Embedding(input_dim=aave_vocab_size, output_dim=embedding_dim)(encoder_input)\n",
    "encoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_lstm2 = LSTM(units, return_sequences=True, return_state=True)\n",
    "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs)\n",
    "encoder_state = [state_h2, state_c2]\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(shape=(None,), dtype='int64', name='decoder_input')\n",
    "decoder_embedding = Embedding(input_dim=sae_vocab_size, output_dim=embedding_dim)(decoder_input)\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_lstm_output, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_state)\n",
    "decoder_lstm2 = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_lstm_output2, _, _ = decoder_lstm2(decoder_lstm_output)\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = Attention(use_scale=True)\n",
    "attention_output = attention_layer([decoder_lstm_output2, encoder_outputs2])\n",
    "\n",
    "# Concatenation\n",
    "decoder_concat_input = Concatenate(axis=-1)([decoder_lstm_output2, attention_output])\n",
    "\n",
    "# Output Layer\n",
    "decoder_dense = Dense(sae_vocab_size, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b4711d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_19 (Embedding)       (None, None, 256)    738816      ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 [(None, None, 1024)  5246976     ['embedding_19[0][0]']           \n",
      "                                , (None, 1024),                                                   \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)       (None, None, 256)    811264      ['decoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)                 [(None, None, 1024)  8392704     ['lstm_22[0][0]']                \n",
      "                                , (None, 1024),                                                   \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " lstm_24 (LSTM)                 [(None, None, 1024)  5246976     ['embedding_20[0][0]',           \n",
      "                                , (None, 1024),                   'lstm_23[0][1]',                \n",
      "                                 (None, 1024)]                    'lstm_23[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_25 (LSTM)                 [(None, None, 1024)  8392704     ['lstm_24[0][0]']                \n",
      "                                , (None, 1024),                                                   \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " attention_3 (Attention)        (None, None, 1024)   1           ['lstm_25[0][0]',                \n",
      "                                                                  'lstm_23[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, None, 2048)   0           ['lstm_25[0][0]',                \n",
      "                                                                  'attention_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, None, 3169)   6493281     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,322,722\n",
      "Trainable params: 35,322,722\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac82ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_input_target(batch):\n",
    "    input_text = batch['aave']\n",
    "    target_text = batch['sae']\n",
    "\n",
    "    input_data = aave_vectorization(input_text)\n",
    "    target_data = sae_vectorization(target_text)\n",
    "\n",
    "    # Ensure all sequences in the batch have the same length\n",
    "    sequence_length = 30\n",
    "    input_data = tf.ensure_shape(input_data, [None, sequence_length])\n",
    "    target_data = tf.ensure_shape(target_data, [None, sequence_length])\n",
    "\n",
    "    return {'encoder_input': input_data, 'decoder_input': target_data[:, :-1]}, target_data[:, 1:]\n",
    "\n",
    "# Apply the function to each item in the dataset\n",
    "train_dataset = train_dataset.map(split_input_target).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(split_input_target).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e349d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 15:43:33.379535: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2249 num_cores: 128 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 268435456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/289 [>.............................] - ETA: 2:41 - loss: 3.3043 - accuracy: 0.6955"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m early_stopping_callback \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     14\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model with validation split and callbacks\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/N/soft/sles15/python/gnu/3.10.5/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "\n",
    "# Callbacks for Early Stopping and Model Checkpoint\n",
    "checkpoint_filepath = '/N/u/saswar/Carbonate/AAVE/'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    verbose=1)\n",
    "\n",
    "# Train the model with validation split and callbacks\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset, callbacks=[early_stopping_callback, model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd86a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9accd7d4-9367-4809-986c-fd8f382bf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting and saving the loss curve\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.savefig('loss_curve_M2.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Function to calculate BLEU score and save results to CSV\n",
    "def calculate_and_save_bleu(model, dataset, filename='translation_results_M2.csv'):\n",
    "    results = []\n",
    "    bleu_scores = []\n",
    "    smoothie = SmoothingFunction().method4 \n",
    "\n",
    "    for batch in dataset:\n",
    "        input_data, target_data = batch\n",
    "        predictions = np.argmax(model.predict(input_data), axis=-1)\n",
    "\n",
    "        for input_seq, pred, actual in zip(input_data['encoder_input'], predictions, target_data):\n",
    "            input_sentence = [aave_vectorization.get_vocabulary()[i] for i in input_seq.numpy() if i != 0]\n",
    "            pred_sentence = [sae_vectorization.get_vocabulary()[i] for i in pred if i != 0]\n",
    "            actual_sentence = [sae_vectorization.get_vocabulary()[i] for i in actual.numpy() if i != 0]\n",
    "\n",
    "            if len(pred_sentence) == 0 or len(actual_sentence) == 0:\n",
    "                continue\n",
    "\n",
    "            bleu_score = sentence_bleu([actual_sentence], pred_sentence, smoothing_function=smoothie)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "            results.append({\n",
    "                'AAVE Sentence': ' '.join(input_sentence),\n",
    "                'Predicted SAE Translation': ' '.join(pred_sentence),\n",
    "                'Target SAE Translation': ' '.join(actual_sentence),\n",
    "                'BLEU Score': bleu_score\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(results).to_csv(filename, index=False)\n",
    "    average_bleu_score = np.mean(bleu_scores) if len(bleu_scores) > 0 else 0.0\n",
    "    return average_bleu_score\n",
    "\n",
    "# Calculate BLEU score, save the results, and print the average BLEU score\n",
    "average_bleu_score = calculate_and_save_bleu(model, test_dataset)\n",
    "print(f\"Overall BLEU Score: {average_bleu_score}\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "best_model.save('best_model_M2.h5')  # Save the full model in HDF5 format\n",
    "\n",
    "print(\"Best model saved as 'best_model_M2.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
